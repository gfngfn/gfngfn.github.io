<!doctype html><html lang=ja><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=stylesheet type=text/css href=https://gfngfn.github.io/css/bootstrap.min.css><link rel=stylesheet type=text/css href=https://gfngfn.github.io/css/style.css><link rel=stylesheet type=text/css href=https://gfngfn.github.io/css/chroma.css><title>ocaml-torchã‚’Apple Siliconã®ãƒã‚·ãƒ³ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦å‹•ã‹ã™ã¾ã§ - gfnweb</title></head><body class="d-flex flex-column upcards-body"><nav id=nav class="navbar navbar-expand-lg navbar-dark bg-dark"><div class=container-fluid><a class=navbar-brand href=https://gfngfn.github.io/ja/>gfnweb</a>
<button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class=nav-item><a class=nav-link href=/ja/><i data-feather=home></i>
Home</a></li><li class=nav-item><a class=nav-link href=/ja/about/><i data-feather=user></i>
Profile</a></li><li class=nav-item><a class=nav-link href=https://github.com/gfngfn><i data-feather=github></i>
GitHub</a></li><li class=nav-item><a class=nav-link href=https://twitter.com/bd_gfngfn><i data-feather=twitter></i>
Twitter/X</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" id=navbarDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i data-feather=file-text></i>Language</a><ul class=dropdown-menu aria-labelledby=navbarDropdown><li><a class=dropdown-item href=https://gfngfn.github.io/posts/2024-11-04-install-ocaml-torch-on-apple-silicon/>English</a></li><li><span class="dropdown-item disabled">æ—¥æœ¬èª</span></li></ul></li></ul></div></div></nav><main class="mb-auto pb-5"><div id=articleHeading class="jumbotron bg-light upcards-single-heading"><div class="mx-auto upcards-single-board"><h1 class=upcards-single-board-title>ocaml-torchã‚’Apple Siliconã®ãƒã‚·ãƒ³ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦å‹•ã‹ã™ã¾ã§</h1><div class=upcards-time-section><p class=upcards-time><time datetime=2024-11-04>2024å¹´11æœˆ4æ—¥</time></p><p class=upcards-time>æœ€çµ‚æ›´æ–°ï¼š <time datetime=2024-11-12>2024å¹´11æœˆ12æ—¥</time></p></div><div><span style=position:relative;z-index:2><a class="btn btn-sm btn-outline-dark tag-btn upcards-tag-button" href=https://gfngfn.github.io/ja/tags/ocaml>OCaml</a>
<a class="btn btn-sm btn-outline-dark tag-btn upcards-tag-button" href=https://gfngfn.github.io/ja/tags/deep-learning>æ·±å±¤å­¦ç¿’</a>
<a class="btn btn-sm btn-outline-dark tag-btn upcards-tag-button" href=https://gfngfn.github.io/ja/tags/memo>ãƒ¡ãƒ¢</a></span></div><div class=mt-3><a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class=twitter-share-button data-show-count=false>Tweet</a></div></div></div><div class=upcards-single-content><div class="mx-auto upcards-single-board"><p>ocaml-torchã‚’Apple Siliconã®ãƒã‚·ãƒ³ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ï¼Œã²ã¨ã¾ãšCPUä¸Šã§å‹•ã‹ã™ã“ã¨ã¯ã§ããŸã®ã§ï¼Œæ‰‹é †ã‚’ãƒ¡ãƒ¢æ›¸ãçš„ã«æ®‹ã—ã¾ã™ï¼ã‚ã‚Šã¨ä¹±é›‘ãªã®ã§ï¼Œé©å®œä¿®æ­£ã™ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼</p><div id=toc class="upcards-toc px-3"><h3 class=mt-0>ç›®æ¬¡</h3><nav id=TableOfContents><ul><li><a href=#ã¯ã˜ã‚ã«>ã¯ã˜ã‚ã«</a></li><li><a href=#1-ã¾ãšã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒä¸€æ—¦æˆåŠŸã™ã‚‹ã¾ã§>1 ã¾ãšã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒä¸€æ—¦æˆåŠŸã™ã‚‹ã¾ã§</a><ul><li><a href=#1-1-libtorchã®æº–å‚™>1-1 LibTorchã®æº–å‚™</a></li><li><a href=#1-2-ç’°å¢ƒå¤‰æ•°-libtorch-ã®è¨­å®š>1-2 ç’°å¢ƒå¤‰æ•° <code>LIBTORCH</code> ã®è¨­å®š</a></li><li><a href=#1-3-janestreettorch-ã®-v0160-ã‚’clone>1-3 <code>janestreet/torch</code> ã® <code>v0.16.0</code> ã‚’clone</a></li><li><a href=#1-4-libtorch-ã¨-torch-ã‚’ãƒ“ãƒ«ãƒ‰>1-4 <code>libtorch</code> ã¨ <code>torch</code> ã‚’ãƒ“ãƒ«ãƒ‰</a></li></ul></li><li><a href=#2-å‹•ã‹ãªã„ã¨ã“ã‚ã‚’ç›´ã™>2 å‹•ã‹ãªã„ã¨ã“ã‚ã‚’ç›´ã™</a><ul><li><a href=#2-1-libtorchã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œå¯èƒ½ã«ã™ã‚‹>2-1 LibTorchã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œå¯èƒ½ã«ã™ã‚‹</a></li><li><a href=#2-2-å®Ÿè£…ä¾‹-examplesmnistml-ã‚’å‹•ã‹ã™æº–å‚™>2-2 å®Ÿè£…ä¾‹ <code>examples/mnist/*.ml</code> ã‚’å‹•ã‹ã™æº–å‚™</a></li><li><a href=#2-3-ä¸å…·åˆã®ä¿®æ­£>2-3 ä¸å…·åˆã®ä¿®æ­£</a></li></ul></li><li><a href=#ã¾ã¨ã‚>ã¾ã¨ã‚</a></li></ul></nav></div><h2 id=ã¯ã˜ã‚ã«>ã¯ã˜ã‚ã«</h2><p>æ·±å±¤å­¦ç¿’é–¢é€£ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚„ãƒ„ãƒ¼ãƒ«ã¯ç‰¹å®šã®è¨ˆç®—æ©Ÿã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„ABIã«ä¾å­˜ã—ãŸå®Ÿè£…ã«ãªã£ã¦ã„ã‚‹ã“ã¨ãŒã—ã°ã—ã°ã‚ã‚Šï¼ŒM1 Macãƒ»M2 Macãªã©Apple Siliconã®ãƒã‚·ãƒ³ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦å‹•ã‹ã™ã®ã¯æ¦‚ã—ã¦æœªã ã«å„ä»‹ãªã‚ˆã†ã§ã™ï¼ä¾‹ãˆã°ï¼ŒPyTorch 2.xè‡ªä½“ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦å‹•ã‹ã™ã®ã¯æ¯”è¼ƒçš„æ˜“ã—ã„ã‚ˆã†ã§ã™ãŒï¼Œ<code>.to(device)</code> ãªã©ã‚’å„æ‰€ã§æŒ‡å®šã™ã‚‹å¿…è¦ã®ã‚ã‚‹ï¼Œä½ç´šãªéƒ¨åˆ†ã‚’ã‚ã¾ã‚Šè¦†ã„éš ã•ãªã„APIã«ãªã£ã¦ã„ã‚‹ã“ã¨ã‚‚ã‚ã£ã¦ã‹ï¼ŒPyTorchã«ä¾å­˜ã—ã¦ã„ã‚‹ãƒ„ãƒ¼ãƒ«ãŒx86_64å‰æã§ã‚ã£ãŸã‚ŠCUDAãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ç’°å¢ƒã§å‹•ãã“ã¨ã‚’å‰æã—ãŸå®Ÿè£…ã«ãªã£ã¦ã„ã¦MPSã§ã¯ä½¿ãˆãªã„ï¼Œã¨ã„ã£ãŸã“ã¨ã‚‚ã‚ˆãã‚ã‚Šã¾ã™ï¼</p><p>PyTorchã®OCamlãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã§ã‚ã‚‹<strong>ocaml-torch</strong>ï¼ˆOPAMä¸Šã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã¨ã—ã¦ã¯ <code>torch</code>ï¼‰ã‚‚ã“ã®ç‚¹ä¾‹å¤–ã§ã¯ãªã„ã‚ˆã†ã§ã™ï¼<code>torch</code> ã¯ <code>libtorch</code> ã¨ã„ã†PyTorch C++ APIã‚’ãƒ©ãƒƒãƒ—ã—ãŸOPAMãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã«ä¾å­˜ã—ã¦ãŠã‚Šï¼Œã“ã® <code>libtorch</code> ã®ãƒªãƒªãƒ¼ã‚¹ãŒ1.7.0ä»¥é™ã¯x86_64ã‚’å‰æã—ã¦ã„ã¦Apple Siliconã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼š</p><div class=upcards-console-block><pre><code>$ opam info libtorch

<><> libtorch: information on all versions ><><><><><><><><><><><><><><><><>  ğŸ«
name                   libtorch
ï¼ˆä¸­ç•¥ï¼‰
all-versions           1.0.0  1.0.1  1.1.0  1.2.0  1.3.0  1.3.1  1.4.0  1.5.0  1.6.0  1.7.0+linux-x86_64
                       1.7.0+macos-x86_64  1.8.0+linux-x86_64  1.8.0+macos-x86_64  1.9.0+linux-x86_64
                       1.9.0+macos-x86_64  1.10.0+linux-x86_64  1.10.0+macos-x86_64  1.12.0+linux-x86_64
                       1.12.0+macos-x86_64  1.13.0+linux-x86_64  1.13.0+macos-x86_64  2.0.0+linux-x86_64
                       2.0.0+macos-x86_64  2.1.2+linux-x86_64  2.2.1+linux-x86_64</code></pre></div><p><code>torch</code> ã‚‚ <code>libtorch</code> ã‚‚GitHubãƒªãƒã‚¸ãƒˆãƒª <a href=https://github.com/janestreet/torch><code>github.com/janestreet/torch</code></a> ã§é–‹ç™ºã•ã‚Œã¦ãŠã‚Š<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>ï¼Œã“ã‚Œã‚’cloneã—ã¦ <code>opam pin</code> ã«ã‚ˆã‚Šã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’è©¦ã¿ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ãŒï¼Œå®Ÿéš›Apple Siliconã®ãƒã‚·ãƒ³ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã‚ˆã†ã¨ã™ã‚‹ã¨ <code>libtorch</code> ã®æ–¹ã®ãƒ“ãƒ«ãƒ‰ã§å¤±æ•—ã™ã‚‹ã‚ˆã†ã§ï¼ŒIssueãŒç«‹ã¦ã‚‰ã‚Œã¦ã„ã¾ã™ï¼š</p><ul><li><a href=https://github.com/janestreet/torch/issues/2>Support for MacOS Arm64 (M1 and M2 series chips) Â· Issue #2 Â· janestreet/torch</a></li></ul><p>ã§ï¼Œã“ã‚Œã«ã¯ã—ã£ã‹ã‚Šã¨ã—ãŸå›ç­”ãŒå¯„ã›ã‚‰ã‚Œã¦ã„ã¾ã™ï¼š</p><blockquote><p>It looks like your problem is that the native libtorch binaries that you downloaded are for Intel rather than Apple Silicon. You can use these binaries by running an Intel build of OCaml through Rosetta. However, if you want to run natively, read on:</p><p>I added more instructions on this in <a href=https://github.com/LaurentMazare/ocaml-torch/issues/76#issuecomment-1627318488>LaurentMazare/ocaml-torch#76 (comment)</a> but will copy here:</p><ul><li>Download <code>libtorch</code> binaries (or build <code>libtorch</code> in your Mac). At the moment there are no official pre-build binaries. I downloaded my (unofficial) binaries from <a href=https://github.com/mlverse/libtorch-mac-m1/releases>https://github.com/mlverse/libtorch-mac-m1/releases</a> .</li><li>Install OCaml >= 4.14 (see here: <a href=https://opam.ocaml.org/packages/torch/>https://opam.ocaml.org/packages/torch/</a>)</li><li>Double check what <code>libtorch</code> version is compatible with the current version of OCaml torch. Version 1.13.1 is the one you want with <code>v0.16.0</code> version of OCaml <code>torch</code>.</li><li>Set the <code>LIBTORCH</code> environment variable to the directory that includes the include and lib directories.</li></ul><p>To install with opam:</p><div class=upcards-code-block><pre><code>opam install torch.v0.16.0 --ignore-constraints-on libtorch</code></pre></div><p>Note that I had to ignore-constraints to avoid failing because libtorch (an OCaml/OPAM library that contains pre-build libtorch binaries for some architectures that do not include M1/M2) is disabled for M1 Mac. Note also that I explicitly had to set the version of the package (JaneStreet version starts with v0 rather than 0) as I otherwise resolve to version 0.10 which is way too old.</p></blockquote><p>è¦ã™ã‚‹ã«ï¼Œå˜ã«ãƒã‚¤ãƒ³ãƒ‰ã•ã‚Œã‚‹LibTorchï¼ˆã‚„ã‚„ã“ã—ã„ã§ã™ãŒï¼ŒOPAMãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ã—ã¦ã® <code>libtorch</code> ã§ã¯ãªãPyTorch C++ APIã®å®Ÿè£…ã®ã“ã¨ã§ã™ï¼ä¸Šè¨˜å›ç­”ä¸­ã§ã¯ã“ã‚Œã‚’æŒ‡ã—ã¦ã€Œ<code>libtorch</code> binariesã€ã¨ã‹å˜ã«ã€Œ<code>libtorch</code>ã€ã¨è¡¨è¨˜ã•ã‚Œã¦ã„ã¾ã™ï¼‰ãŒx86_64ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã—ã¦ãƒ“ãƒ«ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒè¦å› ãªã‚ˆã†ã§ï¼Œè‡ªå‰ã§Apple Siliconå‘ã‘ã«ãƒ“ãƒ«ãƒ‰ã—ãŸLibTorchã‚’ç”¨æ„ã—ã¦ç’°å¢ƒå¤‰æ•° <code>LIBTORCH</code> ã«ãã®ãƒ‘ã‚¹ã‚’è¨­å®šã—ã¦ã‹ã‚‰OPAMãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰ãƒ»ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã¨ã‚ˆã„ï¼Œã¨ã„ã†ã“ã¨ã®ã‚ˆã†ã§ã™ï¼åŠ ãˆã¦ï¼Œã‚ã‚ŠãŒãŸã„ã“ã¨ã«LibTorchã®ãã†ã„ã£ãŸãƒ“ãƒ«ãƒ‰çµæœã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¦ãã‚Œã¦ã„ã‚‹æ–¹ãŒã„ã‚‹ã‚ˆã†ã§ã™ï¼š</p><ul><li><a href=https://github.com/mlverse/libtorch-mac-m1>mlverse/libtorch-mac-m1: LibTorch builds for the M1 Macs</a></li></ul><p>å®Ÿéš›ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã®Releasesã«ãƒ“ãƒ«ãƒ‰æ¸ˆã¿ã®ãƒã‚¤ãƒŠãƒªç¾¤ãŒå…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ï¼š</p><ul><li><a href=https://github.com/mlverse/libtorch-mac-m1/releases>Releases Â· mlverse/libtorch-mac-m1</a></li></ul><p>ã¨ã„ã†ã‚ã‘ã§ã²ã¨ã¾ãšã“ã‚Œã‚’ä¿¡é ¼ã—ã¦ä½¿ã‚ã›ã¦ã‚‚ã‚‰ã„ã¾ã—ã‚‡ã†ï¼ã©ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã™ã¹ãã‹ã§ã™ãŒï¼Œä»¥ä¸‹ã®ã‚ˆã†ãªè€ƒæ…®ã®çµæœä¸Šè¨˜å›ç­”ã¨åŒã˜ã1.13.1ã‚’ä½¿ã†ã“ã¨ã«ã—ã¾ã—ãŸï¼š</p><ul><li><code>torch</code> ã®æœ€æ–°ç‰ˆã¯ <code>v0.17.0</code> ã ãŒï¼Œã“ã‚Œã¯OCaml 5.1.0ä»¥ä¸Šã‚’è¦è«‹ã™ã‚‹ï¼ç­†è€…ã®ç’°å¢ƒã§ã¯ã¾ã OCaml 4.14å°ã‚’ä½¿ã„ç¶šã‘ã¦ã„ã‚‹ã®ã§ï¼Œæ‰‹ã£å–ã‚Šæ—©ãå‹•ã‹ã™ãŸã‚ã«ä¸€æ—¦ã“ã‚Œã¯ã‚„ã‚ã¦ãŠãï¼ˆã©ã†ã—ã¦ã‚‚ç„¡ç†ãªã‚‰OCaml 5.1.0ä»¥ä¸Šã«ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã«ã™ã‚‹ï¼‰ï¼</li><li><code>torch</code> ã®1ã¤å‰ã®ãƒªãƒªãƒ¼ã‚¹ <code>v0.16.0</code> ã¯OCaml 4.14ã§å‹•ãã®ã§ï¼Œã²ã¨ã¾ãšã“ã‚Œã‚’ä½¿ã†ã“ã¨ã‚’è€ƒãˆã‚‹ï¼ã“ã‚Œã®ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ <code>libtorch</code> ã«é–¢ã™ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³åˆ¶ç´„ã¯ <code>"libtorch" {>= "1.13.0" & &lt; "1.14.0"}</code> ã¨ã„ã†è¨˜è¼‰ã«ãªã£ã¦ã„ã‚‹ï¼</li><li>ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ <code>libtorch</code> ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·ã¯ï¼Œãƒã‚¤ãƒ³ãƒ‰ã•ã‚Œã¦ã„ã‚‹LibTorchã¨åŒã˜ã‚‚ã®ã‚’ä½¿ã£ã¦ã„ã‚‹ã‚‰ã—ã„ï¼</li><li>ã¨ã„ã†ã‚ã‘ã§ï¼Œä¸Šè¨˜ãƒªãƒªãƒ¼ã‚¹ã®ã†ã¡ <code>libtorch-v1.13.1.zip</code> ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ã†ã¨ã‚ˆã•ãã†ï¼</li></ul><h2 id=1-ã¾ãšã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒä¸€æ—¦æˆåŠŸã™ã‚‹ã¾ã§>1 ã¾ãšã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒä¸€æ—¦æˆåŠŸã™ã‚‹ã¾ã§</h2><h3 id=1-1-libtorchã®æº–å‚™>1-1 LibTorchã®æº–å‚™</h3><p>ã¾ãšã¯ <a href=https://github.com/mlverse/libtorch-mac-m1/releases>Releases Â· mlverse/libtorch-mac-m1</a> ã‹ã‚‰ <code>libtorch-v1.13.1.zip</code> ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ï¼Œè§£å‡ã—ã¦é…ç½®ã—ã¾ã™ï¼ç½®ãå ´æ‰€ã¯ã©ã“ã§ã‚‚ã‚ˆã„ã§ã™ãŒï¼Œç­†è€…ã¯ã¨ã‚Šã‚ãˆãš <code>$HOME/cloned/libtorch</code> ã«ç½®ãã¾ã—ãŸï¼ã™ãªã‚ã¡ä»¥ä¸‹ã®ã‚ˆã†ãªå…·åˆã§ã™ï¼š</p><div class=upcards-code-block><pre><code>$HOME/cloned/
â””â”€â”€ libtorch/
    â”œâ”€â”€ bin/
    â”œâ”€â”€ include/
    â”œâ”€â”€ lib/
    â””â”€â”€ share/</code></pre></div><h3 id=1-2-ç’°å¢ƒå¤‰æ•°-libtorch-ã®è¨­å®š>1-2 ç’°å¢ƒå¤‰æ•° <code>LIBTORCH</code> ã®è¨­å®š</h3><p>1ã§é…ç½®ã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç’°å¢ƒå¤‰æ•° <code>LIBTORCH</code> ã«è¨­å®šã—ã¾ã™ï¼ˆé©åˆ‡ã«èª­ã¿æ›¿ãˆã¦ãã ã•ã„ï¼‰ï¼š</p><div class=upcards-console-block><pre><code>$ export LIBTORCH="$HOME/cloned/libtorch"</code></pre></div><h3 id=1-3-janestreettorch-ã®-v0160-ã‚’clone>1-3 <code>janestreet/torch</code> ã® <code>v0.16.0</code> ã‚’clone</h3><p>ã“ã‚Œã¯ã‚„ã‚‹ã ã‘ï¼ˆ1ã¨åŒæ§˜ã« <code>cloned/</code> ã‚’ä½¿ã£ã¦ã„ã¾ã™ãŒè‡ªåˆ†ã®å¥½ã¿ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«èª­ã¿æ›¿ãˆã¦ãã ã•ã„ï¼‰ï¼š</p><div class=upcards-console-block><pre><code>$ cd $HOME/cloned
$ git clone https://github.com/janestreet/torch
$ cd torch
$ git checkout v0.16.0</code></pre></div><h3 id=1-4-libtorch-ã¨-torch-ã‚’ãƒ“ãƒ«ãƒ‰>1-4 <code>libtorch</code> ã¨ <code>torch</code> ã‚’ãƒ“ãƒ«ãƒ‰</h3><p>ã•ã¦ï¼Œã“ã“ãŒå°‘ã—ãƒãƒã‚Šã©ã“ã‚ã§ã™ï¼åŸºæœ¬çš„ã«ã¯ä»¥ä¸‹ã‚’å®Ÿè¡Œã™ã‚Œã°ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã‚‹ã®ã§ã™ãŒï¼Œç§ã®ç’°å¢ƒã§ã¯ã“ã‚Œã ã‘ã§ã¯ãƒ€ãƒ¡ã§ã—ãŸï¼š</p><div class=upcards-console-block><pre><code>$ opam pin add .
# ä¸Šè¨˜ã‚³ãƒãƒ³ãƒ‰ã‚’å©ãã ã‘ã§ libtorch ã¨ torch ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã‹è¨Šã‹ã‚Œã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãŒï¼Œ`n`ï¼ˆ=NOï¼‰ã‚’ã‚¿ã‚¤ãƒ—ã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãªã„
$ opam install torch.v0.16.0 --ignore-constraints-on libtorch</code></pre></div><p>å…·ä½“çš„ã«ã¯ï¼Œ<code>libtorch</code> ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«ã¯æˆåŠŸã—ã¾ã™ãŒï¼Œ<code>torch</code> ã®ãƒ“ãƒ«ãƒ‰ã§Cè¨€èªã®æ°´æº–ã®ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¦å¤±æ•—ã—ã¾ã—ãŸï¼š</p><div class=upcards-console-block><pre><code>$ opam install torch.v0.16.0 --ignore-constraints-on libtorch
The following actions will be performed:
=== install 2 packages
  âˆ— libtorch 1.6.0   [required by torch]
  âˆ— torch    v0.16.0

Proceed with âˆ— 2 installations? [y/n] y

<><> Processing actions <><><><><><><><><><><><><><><><><><><><><><><><><><>  ğŸ«
â¬‡ retrieved libtorch.1.6.0  (cached)
â¬‡ retrieved torch.v0.16.0  (cached)
âˆ— installed libtorch.1.6.0
[ERROR] The compilation of torch.v0.16.0 failed at "dune build -p torch -j 7".

#=== ERROR while compiling torch.v0.16.0 ======================================#
# context     2.2.1 | macos/arm64 | ocaml-base-compiler.4.14.1 | https://opam.ocaml.org#56e31a3bc1fd0bfd87e5251972e806b8f78082a5
# path        ~/.opam/4.14.1/.opam-switch/build/torch.v0.16.0
# command     ~/.opam/opam-init/hooks/sandbox.sh build dune build -p torch -j 7
# exit-code   1
# env-file    ~/.opam/log/torch-25254-41b03d.env
# output-file ~/.opam/log/torch-25254-41b03d.out
### output ###
# torch_stubs.c:38971:36: warning: passing 'const char *' to parameter of type 'char *' discards qualifiers [-Wincompatible-pointer-types-discards-qualifiers]
# [...]
#                                    ^~~~~~
# ./torch_api_generated.h:2300:180: note: passing argument to parameter 'pad_mode' here
# void atg_stft_center(tensor *, tensor self, int64_t n_fft, int64_t hop_length_v, int hop_length_null, int64_t win_length_v, int win_length_null, tensor window, int center, char * pad_mode, int normalized, int onesided, int return_complex);
#                                                                                                                                                                                    ^
# 121 warnings and 1 error generated.
ï¼ˆä¸­ç•¥ï¼‰

<><> Error report <><><><><><><><><><><><><><><><><><><><><><><><><><><><><>  ğŸ«
â”Œâ”€ The following actions failed
â”‚ Î» build torch v0.16.0
â””â”€
â”Œâ”€ The following changes have been performed
â”‚ âˆ— install libtorch 1.6.0
â””â”€</code></pre></div><p>ã¡ãªã¿ã«ã“ã“ã§OPAMãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ã—ã¦ã¯ <code>libtorch</code> ã® <code>1.6.0</code> ãŒå…¥ã£ã¦ã—ã¾ã„ã¾ã™ãŒï¼Œãƒã‚¤ãƒ³ãƒ‰ã•ã‚Œã‚‹LibTorchã¯1.13.1ã«ãªã‚‹ã®ã§å•é¡Œãªã„ã‚ˆã†ã§ã™ï¼</p><p>ã‹ãªã‚Šå¤šãã®warningãŒå‡ºã¦ã„ã‚‹ã®ã¯ã•ã¦ãŠãï¼Œãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä¸Šè¨˜ã®å ´åˆã¯ <code>~/.opam/log/torch-22992-7fcee8.out</code>ï¼‰ã‚’grepã—ã¦ã¿ã‚‹ã¨ï¼Œä»¥ä¸‹ã®ã‚ˆã†ãªerrorãŒ <code>/usr/bin/cc</code> ã«ã‚ˆã£ã¦å‡ºã¦ãƒ“ãƒ«ãƒ‰ã«å¤±æ•—ã—ã¦ã„ã¾ã—ãŸï¼š</p><div class=upcards-console-block><pre><code>torch_stubs.c:295:27: error: incompatible function pointer types passing 'void (*)(const char *, void *)' to parameter of type 'void (*)(char *, tensor)' (aka 'void (*)(char *, void *)') [-Wincompatible-function-pointer-types]
   at_load_callback(x280, x281);
                          ^~~~
./torch_api.h:85:46: note: passing argument to parameter 'f' here
void at_load_callback(char *filename, void (*f)(char *, tensor));</code></pre></div><p>ç­†è€…ã®ç’°å¢ƒã® <code>/usr/bin/cc</code> ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç­‰ã¯ä»¥ä¸‹ã§ã™ï¼š</p><div class=upcards-console-block><pre><code>$ /usr/bin/cc --version
Apple clang version 15.0.0 (clang-1500.3.9.4)
Target: arm64-apple-darwin23.6.0
Thread model: posix
InstalledDir: /Library/Developer/CommandLineTools/usr/bin</code></pre></div><p>ã‚¨ãƒ©ãƒ¼å ±å‘Šã«ã‚‚å‡ºã¦ã„ã‚‹ã¨ãŠã‚Šï¼Œ<code>-Wincompatible-function-pointer-types</code> ã¨ã„ã†è¨­å®šã«åŸºã¥ã„ãŸã‚¨ãƒ©ãƒ¼ã§ã‚ã‚‹ã¯ãšãªã®ã§ï¼Œã“ã‚Œã‚’ç„¡åŠ¹ã«ã™ã‚‹ãƒ•ãƒ©ã‚°ã‚’ä¸ãˆã‚‰ã‚Œã‚Œã°é€šã‚Šãã†ã§ã™ï¼ã¨ã„ã†ã‚ã‘ã§ï¼Œ<code>src/wrapper/dune</code> ã«ãã®ã‚ˆã†ãªæŒ‡å®šã‚’è¿½åŠ ã—ã¾ã™ï¼š</p><div class=upcards-code-block><div class=highlight><pre tabindex=0 class=chroma><code class=language-diff data-lang=diff><span class=line><span class=cl> (library (name torch_core) (public_name torch.core) (c_names torch_stubs)
</span></span><span class=line><span class=cl><span class=gi>+ (c_flags :standard -Wno-incompatible-function-pointer-types)
</span></span></span><span class=line><span class=cl><span class=gi></span>  (c_library_flags :standard -lstdc++ (:include c_library_flags.sexp))
</span></span><span class=line><span class=cl>  (cxx_names torch_api) (cxx_flags -std=c++14 -fPIC (:include cxx_flags.sexp))
</span></span><span class=line><span class=cl>  (libraries bigarray ctypes.foreign ctypes.stubs ctypes)
</span></span><span class=line><span class=cl>  (preprocess (pps ppx_jane)))
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl> (rule (targets cxx_flags.sexp c_library_flags.sexp)
</span></span><span class=line><span class=cl>  (deps ../config/discover.exe) (action (bash %{deps})))
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl> (rule (targets torch_bindings.ml) (deps ../stubs/torch_bindings.ml)
</span></span><span class=line><span class=cl>  (action (bash &#34;cp ../stubs/torch_bindings.ml torch_bindings.ml&#34;)))
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl> (rule (targets torch_bindings_generated.ml)
</span></span><span class=line><span class=cl>  (deps ../stubs/torch_bindings_generated.ml)
</span></span><span class=line><span class=cl>  (action
</span></span><span class=line><span class=cl>   (bash
</span></span><span class=line><span class=cl>    &#34;cp ../stubs/torch_bindings_generated.ml torch_bindings_generated.ml&#34;)))
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl> (rule (targets torch_stubs.c torch_generated.ml)
</span></span><span class=line><span class=cl>  (deps ../stubs/torch_gen.exe) (action (bash ./%{deps})))
</span></span></code></pre></div></div><p>branchã‚’åˆ‡ã£ã¦ã“ã®ã‚ˆã†ãªå¤‰æ›´ã‚’commitã—ã¾ã™ï¼ˆcommitã—ãªã„ã¨ï¼Œãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯OPAMãŒç„¡è¦–ã—ã¦ã—ã¾ã†ãŸã‚ã§ã™ï¼<code>--working-dir</code> ã¤ãã§ <code>opam pin</code> ã™ã‚Œã°commitã—ã¦ã„ãªã„å¤‰æ›´ã‚‚åŠ å‘³ã•ã‚Œã‚‹ã®ã§ã™ãŒï¼Œã„ãšã‚Œã«ã—ã¦ã‚‚ä½œæ¥­å±¥æ­´ã‚’æ®‹ã—ã¦ãŠãã®ã«ä¾¿åˆ©ãªã®ã§ã“ã“ã§ã¯commitã—ã¾ã™ï¼‰ï¼š</p><div class=upcards-console-block><pre><code>$ git checkout -b temp-patch
$ git add -A
$ git commit -m "patch \`dune\` as to \`c_flags\`"</code></pre></div><p>ã“ã®å¾Œã«ã‚ã‚‰ãŸã‚ã¦ä»¥ä¸‹ã‚’å©ãã¨ <code>torch</code> ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã—ãŸï¼š</p><div class=upcards-console-block><pre><code>$ opam pin add .
# libtorchã«é–¢ã™ã‚‹ä¾å­˜åˆ¶ç´„ãŒå……è¶³ã•ã‚Œã¦ã„ãªã„ã®ã§ [ERROR] ã¨å‡ºãŸã‚Šã™ã‚‹ãŒï¼Œç„¡è¦–ã—ã¦OK
$ opam install torch.v0.16.0 --ignore-constraints-on libtorch</code></pre></div><p>ã¨ã„ã†ã‚ã‘ã§ã“ã“ã¾ã§ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¯ã§ãã¾ã—ãŸãŒï¼Œå®Ÿã¯ã“ã®ã¾ã¾ã ã¨å‹•ã‹ãªã„ã®ã§æ¬¡ç« ã§ä¿®æ­£ã‚’æ–½ã—ã¦ã„ãã¾ã™ï¼</p><h2 id=2-å‹•ã‹ãªã„ã¨ã“ã‚ã‚’ç›´ã™>2 å‹•ã‹ãªã„ã¨ã“ã‚ã‚’ç›´ã™</h2><h3 id=2-1-libtorchã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œå¯èƒ½ã«ã™ã‚‹>2-1 LibTorchã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œå¯èƒ½ã«ã™ã‚‹</h3><p>ã¾ãšã¯è©¦ã—ã« <code>utop</code><sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>ã§ <code>torch</code> ãŒèª­ã¿è¾¼ã‚ã‚‹ã‹è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š</p><div class=upcards-console-block><pre><code>$ utop
ï¼ˆä¸­ç•¥ï¼‰
utop # #require "torch";;
Cannot load required shared library dlltorch_core_stubs.
Reason: $HOME/.opam/4.14.1/lib/stublibs/dlltorch_core_stubs.so: dlopen($HOME/.opam/4.14.1/lib/stublibs/dlltorch_core_stubs.so, 0x000A): Library not loaded: @rpath/libc10.dylib
  Referenced from: <93108957-433A-3A67-8E42-77C8F6184B1D> $HOME/.opam/4.14.1/lib/stublibs/dlltorch_core_stubs.so
  Reason: tried: '$HOME/cloned/libtorch/lib/libc10.dylib' (code signature in <ï¼ˆä¸­ç•¥ï¼‰> '$HOME/cloned/libtorch/lib/libc10.dylib' not valid for use in process: library load disallowed by system policy), 'ï¼ˆä¸­ç•¥ï¼‰' (no such file), '$HOME/cloned/libtorch/lib/libc10.dylib' (code signature in <ï¼ˆä¸­ç•¥ï¼‰> '$HOME/cloned/libtorch/lib/libc10.dylib' not valid for use in process: library load disallowed by system policy), 'ï¼ˆä¸­ç•¥ï¼‰' (no such file).
Error: Reference to undefined global `Torch_core__Wrapper'</code></pre></div><p>ç­†è€…ã®ç’°å¢ƒã ã¨OSã«ã‚ˆã£ã¦ <code>$LIBTORCH/lib/libc10.dylib</code> ã®èª­ã¿è¾¼ã¿ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¾ã—ãŸï¼permissionä¸Šã¯å®Ÿè¡Œå¯èƒ½ã§ã—ãŸãŒï¼Œãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµŒç”±ã§è½ã¨ã—ã¦ããŸãƒ•ã‚¡ã‚¤ãƒ«ãªã®ã§ï¼ŒOSãŒpermissionã¨ã¯åˆ¥ã®ä»•çµ„ã¿ã«ã‚ˆã£ã¦å®Ÿè¡Œã§ããªã„ã‚‚ã®ã¨æ‰±ã£ã¦ã„ã‚‹ã‚ˆã†ã§ã™ï¼LibTorchã‚’è‡ªå·±è²¬ä»»ã§ä¿¡é ¼ã™ã‚‹ã“ã¨ã«ã—ï¼Œå®Ÿè¡Œå¯èƒ½ã«ã—ã¾ã—ã‚‡ã†ï¼ã“ã‚Œã¯ <code>xattr</code> ã¨ã„ã†ã‚³ãƒãƒ³ãƒ‰ã§è¨­å®šã§ãã‚‹ã‚ˆã†ã§ã™ï¼ã¾ãšï¼Œ<code>libc10.dylib</code> ã®å®Ÿè¡ŒãŒãŸã—ã‹ã«ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ï¼š</p><div class=upcards-console-block><pre><code>$ cd $LIBTORCH
$ xattr lib/libc10.dylib
com.apple.quarantine</code></pre></div><p>å®Ÿè¡ŒãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ <code>com.apple.quarantine</code> ãŒä»˜ä¸ã•ã‚Œã¦ã„ã¾ã™ï¼ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿¡ç”¨ã—ã¦ã‚ˆã„ã¨åˆ¤æ–­ã—ãŸã‚‰ï¼Œ<code>-d</code> ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã«ã‚ˆã£ã¦ <code>com.apple.quarantine</code> ã‚’å‰Šé™¤ã—ã¾ã™ï¼š</p><div class=upcards-console-block><pre><code>$ xattr -d com.apple.quarantine lib/libc10.dylib</code></pre></div><p>ã“ã‚Œã§å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸï¼åŒæ§˜ã®å‡¦ç†ã‚’ã‚ã¨2ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦ã‚‚è¡Œãªã„ã¾ã™ï¼š</p><div class=upcards-console-block><pre><code>$ xattr -d com.apple.quarantine lib/libtorch_cpu.dylib
$ xattr -d com.apple.quarantine lib/libtorch.dylib</code></pre></div><p>ã“ã‚Œã§ã²ã¨ã¾ãšèª­ã¿è¾¼ã¿è‡ªä½“ã¯ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š</p><div class=upcards-console-block><pre><code>$ utop
ï¼ˆä¸­ç•¥ï¼‰
utop # #require "torch";;</code></pre></div><h3 id=2-2-å®Ÿè£…ä¾‹-examplesmnistml-ã‚’å‹•ã‹ã™æº–å‚™>2-2 å®Ÿè£…ä¾‹ <code>examples/mnist/*.ml</code> ã‚’å‹•ã‹ã™æº–å‚™</h3><p>MNISTã®å­¦ç¿’ã®ä¾‹ <code>examples/mnist/{linear,nn,conv}.ml</code> ãŒãƒªãƒã‚¸ãƒˆãƒªã«ã‚ã‚‹ã®ã§ï¼Œå‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼<code>examples/mnist/README.md</code> ã«ã‚ˆã‚‹ã¨ï¼Œãƒªãƒã‚¸ãƒˆãƒªã« <code>data/</code> ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã¤ãã£ã¦MNISTã®è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’é…ç½®ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã¨ã®ã“ã¨ãªã®ã§ï¼Œã¾ãšã¯ãã®ã‚ˆã†ã«é…ç½®ã—ã¾ã™ï¼MNISTã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ä»¥ä¸‹ã§é…å¸ƒã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã§ã™ï¼š</p><ul><li><a href=http://yann.lecun.com/exdb/mnist/>http://yann.lecun.com/exdb/mnist/</a></li></ul><p>â€¦â€¦ãªã®ã§ã™ãŒï¼Œå°‘ãªãã¨ã‚‚ç­†è€…ãŒè¦‹ãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°ã ã¨HTTPSã®è¨¼æ˜æ›¸ãŒåˆ‡ã‚Œã¦ãŠã‚Šï¼Œã‹ã¤ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®ãƒªãƒ³ã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã¨Forbiddenã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸï¼Kaggleã§é…å¸ƒã•ã‚Œã¦ã„ãŸã®ã§ã“ã¡ã‚‰ã‚’ä½¿ã‚ã›ã¦ã‚‚ã‚‰ã†ã“ã¨ã«ã—ã¾ã™ï¼š</p><ul><li><a href=https://www.kaggle.com/datasets/hojjatk/mnist-dataset>https://www.kaggle.com/datasets/hojjatk/mnist-dataset</a></li></ul><p>ã“ã“ã§é…å¸ƒã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã¯ãƒ•ã‚¡ã‚¤ãƒ«åãŒå¤§å…ƒã®é…å¸ƒã¨è‹¥å¹²é•ã£ã¦ã„ã‚‹ã®ã§ï¼Œç›´ã—ã¦ <code>data/</code> ã«ä»¥ä¸‹ã®ã‚ˆã†ã«é…ç½®ã—ã¾ã™ï¼ˆãã‚Œãã‚Œé€”ä¸­ã®ãƒ”ãƒªã‚ªãƒ‰ã‚’ãƒã‚¤ãƒ•ãƒ³ã«å¤‰ãˆã‚‹å¿…è¦ãŒã‚ã‚‹ï¼<code>{t10k,train}-images-idx3-ubyte</code> ã¯ãã‚Œãã‚Œzipãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£å‡ã—ãŸã‚‚ã®ï¼‰ï¼š</p><div class=upcards-code-block><pre><code>torch/
â””â”€â”€ data/
      â”œâ”€â”€ t10k-images-idx3-ubyte
      â”œâ”€â”€ t10k-labels-idx1-ubyte
      â”œâ”€â”€ train-images-idx3-ubyte
      â””â”€â”€ train-labels-idx1-ubyte</code></pre></div><p>ã¾ãŸï¼Œ<code>examples/mnist/dune</code> ãŒ <code>v0.16.0</code> ã ã¨ç©ºãƒ•ã‚¡ã‚¤ãƒ«ã«ãªã£ã¦ã„ã‚‹ã®ã§ï¼Œãƒ“ãƒ«ãƒ‰ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã«ä»¥ä¸‹ã‚’æ›¸ãè¾¼ã¿ã¾ã™ï¼ˆ<code>v0.17.0</code> ã‹ã‚‰å–ã£ã¦ããŸã‚‚ã®ï¼‰ï¼š</p><div class=upcards-code-block><pre><code>(executables
 (modes byte exe)
 (names conv linear nn)
 (libraries stdio torch unix)
 (preprocess
  (pps ppx_jane)))</code></pre></div><p>ã“ã‚Œã§æº–å‚™å®Œäº†ã§ï¼Œå®Ÿéš›ã¾ãšå˜ç´”ãªç·šå‹å›å¸°ã§ã‚ã‚‹ <code>linear.ml</code> ã‚’ãƒ“ãƒ«ãƒ‰ã—ã¦ã¿ã‚‹ã¨æˆåŠŸã¯ã—ã¾ã™ï¼š</p><div class=upcards-console-block><pre><code>$ dune build examples/mnist/linear.exe</code></pre></div><p>ã—ã‹ã—ï¼Œã§ãã‚ãŒã£ãŸãƒã‚¤ãƒŠãƒªã‚’å®Ÿè¡Œã—ã¦ã¿ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«è½ã¡ã¾ã™<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>ï¼š</p><div class=upcards-console-block><pre><code>$ ./_build/default/examples/mnist/linear.exe
libc++abi: terminating due to uncaught exception of type c10::Error: The size of tensor a (10) must match the size of tensor b (10000) at non-singleton dimension 0
Exception raised from infer_size_impl at ï¼ˆä¸­ç•¥ï¼‰/libtorch-mac-m1/libtorch-mac-m1/pytorch/aten/src/ATen/ExpandUtils.cpp:35 (most recent call first):
frame #0: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 92 (0x100c1952c in libc10.dylib)
frame #1: at::infer_size_dimvector(c10::ArrayRef<long long>, c10::ArrayRef<long long>) + 376 (0x10ac6e35c in libtorch_cpu.dylib)
frame #2: at::TensorIteratorBase::compute_shape(at::TensorIteratorConfig const&) + 456 (0x10acbba90 in libtorch_cpu.dylib)
frame #3: at::TensorIteratorBase::build(at::TensorIteratorConfig&) + 520 (0x10acb6f8c in libtorch_cpu.dylib)
frame #4: at::TensorIteratorBase::build_borrowing_comparison_op(at::TensorBase const&, at::TensorBase const&, at::TensorBase const&) + 232 (0x10acb7960 in libtorch_cpu.dylib)
frame #5: at::(anonymous namespace)::wrapper_eq_Tensor(at::Tensor const&, at::Tensor const&) + 104 (0x10bf34c80 in libtorch_cpu.dylib)
frame #6: c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail::wrapfunctionintofunctor_<c10::compiletimefunctionpointer<at::tensor (c10::dispatchkeyset, at::tensor const&, at::tensor const&), &torch::autograd::variabletype::(anonymous namespace)::eq_tensor(c10::dispatchkeyset, at::tensor const&, at::tensor const&)>, at::Tensor, c10::guts::typelist::typelist<c10::dispatchkeyset, at::tensor const&, at::tensor const&>>, at::Tensor (c10::DispatchKeySet, at::Tensor const&, at::Tensor const&)>::call(c10::OperatorKernel*, c10::DispatchKeySet, at::Tensor const&, at::Tensor const&) + 116 (0x10d456a08 in libtorch_cpu.dylib)
frame #7: at::_ops::eq_Tensor::call(at::Tensor const&, at::Tensor const&) + 284 (0x10b887ecc in libtorch_cpu.dylib)
frame #8: at::eq(at::Tensor const&, at::Tensor const&) + 40 (0x101457cb0 in dlltorch_core_stubs.so)
frame #9: atg_eq_tensor + 40 (0x101457b88 in dlltorch_core_stubs.so)
frame #10: caml__1017_atg_eq_tensor + 36 (0x1013ada70 in dlltorch_core_stubs.so)
frame #11: caml_interprete + 7760 (0x10093b370 in ocamlrun)
frame #12: caml_main + 1244 (0x10093d8e4 in ocamlrun)
frame #13: main + 16 (0x100960a14 in ocamlrun)
frame #14: start + 2476 (0x1816b3154 in dyld)</code></pre></div><p>ãƒ­ã‚°ã‚’è¦‹ã‚‹ã¨ï¼Œã©ã†ã‚„ã‚‰ãƒ†ãƒ³ã‚½ãƒ«ã®ã‚µã‚¤ã‚ºã®ä¸æ•´åˆã«ã‚ˆã‚Šå¤±æ•—ã—ã¦ã„ã‚‹ã‚ˆã†ã§ã™ï¼ã¨ã„ã†ã‚ã‘ã§æ¬¡ç¯€ã§ã¯ã“ã‚Œã‚’ç›´ã—ã¾ã™ï¼</p><h3 id=2-3-ä¸å…·åˆã®ä¿®æ­£>2-3 ä¸å…·åˆã®ä¿®æ­£</h3><p>å‰ç¯€æœ€å¾Œã§å‡ºã¦ããŸã‚¨ãƒ©ãƒ¼ã®åŸå› ã®èª¿æŸ»ã«ã¯æ•°æ™‚é–“ã»ã©è²»ã‚„ã•ã‚Œã¾ã—ãŸãŒï¼Œçµè«–ã‹ã‚‰è¨€ã†ã¨ <code>torch</code> ã® <code>v0.16.0</code> ã«æ½œã‚“ã§ã„ã‚‹é‡å¤§ãªä¸å…·åˆãŒåŸå› ã§ã—ãŸï¼ã¾ãŸï¼ŒåŸå› ã«æ°—ã¥ã„ãŸå¾Œã«ç¢ºèªã—ãŸã¨ã“ã‚ï¼Œ<code>v0.17.0</code> ã§ã¯ä¿®æ­£ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã§ã™ï¼</p><p>å…·ä½“çš„ã«ã¯ï¼Œ<code>Torch.Tensor.argmax</code> ã®å®Ÿè£…ã«é–“é•ã„ãŒã‚ã‚Šï¼Œã¾ãŸå…·ä½“ä¾‹ä¸­ã§ã® <code>argmax</code> ã®ä½¿ã„æ–¹ã«ã‚‚èª¤ã‚ŠãŒã‚ã‚Šã¾ã—ãŸï¼ä»¥ä¸‹ã®ã‚ˆã†ãªä¿®æ­£ãŒå¿…è¦ã§ã™ï¼ˆã¤ã„ã§ã« <code>argmin</code> ã‚‚ä¿®æ­£ã—ã¦ã„ã¾ã™ï¼‰ï¼š</p><p><code>src/wrapper/wrapper_generated.ml</code>:</p><div class=upcards-code-block><div class=highlight><pre tabindex=0 class=chroma><code class=language-diff data-lang=diff><span class=line><span class=cl> let argmax self ~dim ~keepdim =
</span></span><span class=line><span class=cl>   let out__ = CArray.make t 1 in
</span></span><span class=line><span class=cl><span class=gd>-  stubs_argmax (CArray.start out__) self  (match dim with | None -&gt; Int64.zero | Some v -&gt; Int64.of_int v) (match dim with | Some _ -&gt; 1 | None -&gt; 0)  (if keepdim then 1 else 0);
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+  stubs_argmax (CArray.start out__) self  (match dim with | None -&gt; Int64.zero | Some v -&gt; Int64.of_int v) (match dim with | Some _ -&gt; 0 | None -&gt; 1) (if keepdim then 1 else 0);
</span></span></span><span class=line><span class=cl><span class=gi></span>   let t0 = CArray.get out__ 0 in
</span></span><span class=line><span class=cl>   Gc.finalise C.Tensor.free t0;
</span></span><span class=line><span class=cl>   t0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl> let argmax_out ~out self ~dim ~keepdim =
</span></span><span class=line><span class=cl>   let out__ = CArray.make t 1 in
</span></span><span class=line><span class=cl><span class=gd>-  stubs_argmax_out (CArray.start out__) out self  (match dim with | None -&gt; Int64.zero | Some v -&gt; Int64.of_int v) (match dim with | Some _ -&gt; 1 | None -&gt; 0)  (if keepdim then 1 else 0);
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+  stubs_argmax_out (CArray.start out__) out self  (match dim with | None -&gt; Int64.zero | Some v -&gt; Int64.of_int v) (match dim with | Some _ -&gt; 0 | None -&gt; 1)  (if keepdim then 1 else 0);
</span></span></span><span class=line><span class=cl><span class=gi></span>   let t0 = CArray.get out__ 0 in
</span></span><span class=line><span class=cl>   Gc.finalise C.Tensor.free t0;
</span></span><span class=line><span class=cl>   t0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl> let argmin self ~dim ~keepdim =
</span></span><span class=line><span class=cl>   let out__ = CArray.make t 1 in
</span></span><span class=line><span class=cl><span class=gd>-  stubs_argmin (CArray.start out__) self  (match dim with | None -&gt; Int64.zero | Some v -&gt; Int64.of_int v) (match dim with | Some _ -&gt; 1 | None -&gt; 0)  (if keepdim then 1 else 0);
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+  stubs_argmin (CArray.start out__) self  (match dim with | None -&gt; Int64.zero | Some v -&gt; Int64.of_int v) (match dim with | Some _ -&gt; 0 | None -&gt; 1)  (if keepdim then 1 else 0);
</span></span></span><span class=line><span class=cl><span class=gi></span>   let t0 = CArray.get out__ 0 in
</span></span><span class=line><span class=cl>   Gc.finalise C.Tensor.free t0;
</span></span><span class=line><span class=cl>   t0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl> let argmin_out ~out self ~dim ~keepdim =
</span></span><span class=line><span class=cl>   let out__ = CArray.make t 1 in
</span></span><span class=line><span class=cl><span class=gd>-  stubs_argmin_out (CArray.start out__) out self  (match dim with | None -&gt; Int64.zero | Some v -&gt; Int64.of_int v) (match dim with | Some _ -&gt; 1 | None -&gt; 0)  (if keepdim then 1 else 0);
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+  stubs_argmin_out (CArray.start out__) out self  (match dim with | None -&gt; Int64.zero | Some v -&gt; Int64.of_int v) (match dim with | Some _ -&gt; 0 | None -&gt; 1)  (if keepdim then 1 else 0);
</span></span></span><span class=line><span class=cl><span class=gi></span>   let t0 = CArray.get out__ 0 in
</span></span><span class=line><span class=cl>   Gc.finalise C.Tensor.free t0;
</span></span><span class=line><span class=cl>   t0
</span></span></code></pre></div></div><p><code>examples/mnist/linear.ml</code>:</p><div class=upcards-code-block><div class=highlight><pre tabindex=0 class=chroma><code class=language-diff data-lang=diff><span class=line><span class=cl>     (* Compute the validation error. *)
</span></span><span class=line><span class=cl>     let test_accuracy =
</span></span><span class=line><span class=cl><span class=gd>-      Tensor.(argmax (model test_images) = test_labels)
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+      Tensor.(argmax ~dim:1 (model test_images) = test_labels)
</span></span></span><span class=line><span class=cl><span class=gi></span>       |&gt; Tensor.to_kind ~kind:(T Float)
</span></span><span class=line><span class=cl>       |&gt; Tensor.sum
</span></span><span class=line><span class=cl>       |&gt; Tensor.float_value
</span></span></code></pre></div></div><p><code>src/torch/dataset_helper.ml</code>:</p><div class=upcards-code-block><div class=highlight><pre tabindex=0 class=chroma><code class=language-diff data-lang=diff><span class=line><span class=cl>       let batch_accuracy =
</span></span><span class=line><span class=cl><span class=gd>-        Tensor.(argmax predicted_labels = labels)
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+        Tensor.(argmax ~dim:1 predicted_labels = labels)
</span></span></span><span class=line><span class=cl><span class=gi></span>         |&gt; Tensor.to_kind ~kind:(T Float)
</span></span><span class=line><span class=cl>         |&gt; Tensor.sum
</span></span><span class=line><span class=cl>         |&gt; Tensor.float_value
</span></span></code></pre></div></div><p>ã“ã‚Œã§MNISTã®å­¦ç¿’ãŒãã‚Œãã‚Œå‹•ãã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š</p><div class=upcards-console-block><pre><code>$ ./_build/default/examples/mnist/linear.exe
1 2.302585 68.08%
2 1.508147 60.77%
3 1.387576 52.54%
4 1.578871 64.46%
5 1.706852 60.46%
6 1.193671 61.55%
7 1.395118 70.66%
8 1.290251 70.44%
9 0.891794 66.76%
10 0.934383 71.84%
11 1.107920 73.78%
ï¼ˆä¸­ç•¥ï¼‰
193 0.315388 91.65%
194 0.315182 91.67%
195 0.314978 91.66%
196 0.314774 91.66%
197 0.314573 91.67%
198 0.314373 91.68%
199 0.314174 91.68%
200 0.313977 91.68%</code></pre></div><div class=upcards-console-block><pre><code>$ dune build examples/mnist/nn.exe
$ ./_build/default/examples/mnist/nn.exe
50 0.423307 89.46%
100 0.290042 92.06%
150 0.235908 93.36%
200 0.195982 94.31%
250 0.165280 94.96%
ï¼ˆä¸­ç•¥ï¼‰
800 0.037816 97.30%
850 0.033508 97.34%
900 0.029695 97.39%
950 0.026319 97.42%
1000 0.023346 97.44%</code></pre></div><div class=upcards-console-block><pre><code>$ dune build examples/mnist/conv.exe
$ ./_build/default/examples/mnist/conv.exe
50 0.304574 93.58%
100 0.160071 96.40%
150 0.094311 97.60%
200 0.110899 97.92%
250 0.088540 97.92%
ï¼ˆä¸­ç•¥ï¼‰
4600 0.021709 99.12%
4650 0.030229 99.18%
4700 0.013466 99.01%
4750 0.005627 99.04%
4800 0.000020 99.11%
4850 0.002961 99.02%
4900 0.010990 99.09%
4950 0.013369 99.11%
5000 0.000920 99.20%</code></pre></div><p>æ­£è§£ç‡ã‹ã‚‰å®Ÿéš›ã«å­¦ç¿’ã‚‚ã†ã¾ãã„ã£ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ï¼ã‚„ã£ãŸãœï¼</p><h2 id=ã¾ã¨ã‚>ã¾ã¨ã‚</h2><p>ã¨ã„ã†ã‚ã‘ã§ã„ã‚ã„ã‚ãªè½ã¨ã—ç©´ãŒã‚ã‚Šã¾ã—ãŸãŒã²ã¨ã¾ãšCPUã§ocaml-torchã‚’å‹•ã‹ã™ã“ã¨ã¯ã§ãã¾ã—ãŸï¼ã‚ã¨ã¯MPSã§å‹•ã‹ã›ãŸã‚‰ä¸‡ã€…æ­³ã§ï¼Œocaml-torchã®APIä¸Šã¯å¤šå°‘æ‹¡å¼µã™ã‚Œã°å¯èƒ½ãã†ã§ã¯ã‚ã‚‹ã®ã§ï¼Œãã®ã†ã¡åŠ ç­†ã™ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>ã‚‚ã¨ã‚‚ã¨ <a href=https://github.com/LaurentMazare/ocaml-torch><code>github.com/LaurentMazare/ocaml-torch</code></a> ã§å€‹äººé–‹ç™ºã•ã‚Œã¦ã„ãŸã‚‚ã®ãŒ2023å¹´4æœˆé ƒã«ç¾ãƒªãƒã‚¸ãƒˆãƒªã¸ã¨ç§»ç®¡ã•ã‚ŒãŸã‚ˆã†ã§ã™ï¼&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>OCamlã®å¯¾è©±ç’°å¢ƒã®ã²ã¨ã¤ï¼<code>opam install utop</code> ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ï¼&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>ã¡ãªã¿ã«ï¼Œã“ã“ã®ã‚¨ãƒ©ãƒ¼ã§å‡ºã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã§ã€Œ<code>ï¼ˆä¸­ç•¥ï¼‰</code>ã€ã¨ã—ãŸéƒ¨åˆ†ã«ã¯ãŠãã‚‰ãLibTorchã®Apple Siliconå‘ã‘ãƒ“ãƒ«ãƒ‰ã‚’ã¤ãã£ãŸä½œè€…ã®æ–¹ã®ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã‚ã‚ã†ãƒ‘ã‚¹ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ï¼æ„å›³ã›ãšãƒã‚¤ãƒŠãƒªä¸­ã«ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã—ã¾ã£ãŸã‚‚ã®ã¨æ€ã‚ã‚Œã‚‹ã®ã§ï¼Œå¿µã®ãŸã‚ä¼ã›ã¾ã—ãŸï¼&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></div><script type=text/javascript>const pageNavbarHeight=50,fixedTop=30;function setTocPosition(e){const t=document.documentElement.scrollTop;t<e?tocElement.style.top=""+(fixedTop+(e-t))+"px":tocElement.style.top=""+fixedTop+"px"}const tocElement=document.getElementById("toc");tocElement!==null&&window.addEventListener("load",n=>{const t=document.getElementById("articleHeading").offsetHeight,e=t+pageNavbarHeight;window.addEventListener("scroll",t=>{setTocPosition(e)}),setTocPosition(e)})</script><script async src=https://platform.twitter.com/widgets.js></script></main><footer class="footer py-3 bg-light"><p class="footer text-center">(c) 2024 Copyright: Takashi Suwa</p></footer><script src=https://gfngfn.github.io/js/bootstrap.bundle.min.js></script>
<script src=https://gfngfn.github.io/js/masonry.pkgd.min.js></script>
<script src=https://gfngfn.github.io/js/feather.min.js></script>
<script>feather.replace()</script><script>window.addEventListener("load",function(){var t,e=document.getElementById("grid");e!==null&&(t=new Masonry(e,{itemSelector:".upcards-grid-item",horizontalOrder:!0,fitWidth:!0,gutter:0}))})</script></body></html>